cuDNN version:  7401
Number of GPUs:  1
Using /tmp/torch_extensions as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /tmp/torch_extensions/test_from_cpp/build.ninja...
Building extension module test_from_cpp...
ninja: no work to do.
Loading extension module test_from_cpp...
All parameters:
>>> cutoff_1: 7.700000e+00
>>> cutoff_2: 8.000000e+00
>>> cutoff_3: 0.000000e+00
>>> cutoff_max: 8.000000e+00
>>> N_types_all_frame:  2
>>> type_index_all_frame: [15, 79]
>>> N_Atoms_max: 28
>>> SEL_A_max: 575
>>> Nframes_tot:  2
>>> sym_coord_type:  1
>>> N_sym_coord: 2300
>>> batch_size:  2
>>> stop_epoch:  1
>>> num_filter_layer:  3
>>> filter_neuron: [116, 114, 58]
>>> axis_neuron:  4
>>> num_fitting_layer:  4
>>> fitting_neuron: [280, 205, 93, 70]
>>> start_lr: 5.000000e-04
>>> (Not used)decay_steps: -1
>>> decay_epoch:  1
>>> decay_rate: 9.500000e-01
>>> start_pref_e: 1.000000e+00
>>> limit_pref_e: 1.000000e+00
>>> start_pref_f: 1.000000e+04
>>> limit_pref_f: 1.000000e+00
>>> check_step: 1000
>>> output_epoch: 10
>>> save_epoch: 10

Total number of frames:  2
Number of atoms aligned:  28
COORD_Reshape: shape =  (2, 84)
FORCE_Reshape: shape =  (2, 84)
TYPE_Reshape: shape =  (2, 28)
NEI_IDX_Reshape: shape =  (2, 16100)
NEI_COORD_Reshape: shape =  (2, 48300)
NEI_TYPE_Reshape: shape =  (32200,)
Data pre-processing complete. Building net work.

one_batch_net(
  (batch_norm): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (filter_input): ModuleList(
    (0): ModuleList(
      (0): Linear(in_features=1, out_features=116, bias=True)
      (1): Linear(in_features=1, out_features=116, bias=True)
    )
    (1): ModuleList(
      (0): Linear(in_features=1, out_features=116, bias=True)
      (1): Linear(in_features=1, out_features=116, bias=True)
    )
  )
  (filter_hidden): ModuleList(
    (0): ModuleList(
      (0): ModuleList(
        (0): Linear(in_features=116, out_features=114, bias=True)
        (1): Linear(in_features=114, out_features=58, bias=True)
      )
      (1): ModuleList(
        (0): Linear(in_features=116, out_features=114, bias=True)
        (1): Linear(in_features=114, out_features=58, bias=True)
      )
    )
    (1): ModuleList(
      (0): ModuleList(
        (0): Linear(in_features=116, out_features=114, bias=True)
        (1): Linear(in_features=114, out_features=58, bias=True)
      )
      (1): ModuleList(
        (0): Linear(in_features=116, out_features=114, bias=True)
        (1): Linear(in_features=114, out_features=58, bias=True)
      )
    )
  )
  (fitting_input): ModuleList(
    (0): Linear(in_features=232, out_features=280, bias=True)
    (1): Linear(in_features=232, out_features=280, bias=True)
  )
  (fitting_hidden): ModuleList(
    (0): ModuleList(
      (0): Linear(in_features=280, out_features=205, bias=True)
      (1): Linear(in_features=205, out_features=93, bias=True)
      (2): Linear(in_features=93, out_features=70, bias=True)
    )
    (1): ModuleList(
      (0): Linear(in_features=280, out_features=205, bias=True)
      (1): Linear(in_features=205, out_features=93, bias=True)
      (2): Linear(in_features=93, out_features=70, bias=True)
    )
  )
  (fitting_out): ModuleList(
    (0): Linear(in_features=70, out_features=1, bias=True)
    (1): Linear(in_features=70, out_features=1, bias=True)
  )
)
Number of parameters in the net: 378324
Start training using device:  cuda , count:  1
LR update: lr = 0.000500
Force check:
 tensor([[ 1.7060271724e-03,  2.8434292300e-02,  4.4665899356e-02,
         -6.6549265015e-02, -3.4068836534e-02, -7.6675739064e-02,
          1.7887495020e-01,  1.9960284918e-01, -1.2781651496e-01,
         -9.0096678369e-02,  1.3241403016e-02, -1.4288656194e-01,
         -8.8363372512e-02, -1.7299029720e-02,  2.1519378285e-01,
         -1.9833611995e-01, -1.1579121404e-01, -1.7538903144e-01,
          5.8948924825e-02, -1.4807854359e-01, -3.3300979167e-01,
          7.2518162105e-02,  1.3803633096e-01,  1.3978702349e-01,
         -7.6270883142e-02,  2.9225809508e-01,  1.1498401610e-02,
          2.0822054857e-02, -1.8905385533e-01,  1.6069777334e-01,
          2.9429450817e-02,  6.0470636944e-03, -3.5655590863e-02,
         -1.0465749112e-02,  1.3036835003e-02,  9.5043007316e-02,
         -1.2253250892e-01, -9.3789447386e-02, -2.7620326794e-03,
          6.0588971495e-02, -2.9407375180e-02,  6.7443206338e-03,
         -1.3193492846e-02, -8.6534546892e-03,  8.7969026002e-02,
          8.3315574719e-03,  1.1996969918e-03, -4.2784437637e-02,
         -2.5601225063e-02, -3.1378961527e-02, -2.7033415268e-02,
         -1.0358486221e-02,  6.1805584478e-04,  5.3592431411e-02,
          3.7763401709e-02, -1.1121932078e-01, -1.8125387641e-03,
          1.7227758280e-03,  1.5827155501e-02, -4.9935663950e-02,
         -7.7500632139e-03, -7.9259734979e-02,  8.8357358861e-02,
         -9.4653751654e-03,  7.2795269975e-03, -1.6930966874e-02,
          6.2310161113e-02, -7.0813754169e-02,  5.0803587649e-02,
          5.5649305332e-02,  4.2330975566e-02,  6.4458482560e-02,
         -1.6516176188e-02, -1.7082318653e-02, -2.9163023242e-02,
          1.2985487471e-01,  7.0396773049e-02,  5.9805530523e-02,
         -9.9321620472e-03,  6.2836853599e-02,  1.9552836438e-02,
          2.6910940123e-02,  5.4749939773e-02, -3.6314153689e-02],
        [-1.4714938723e-02,  4.0373058113e-02,  3.2572298992e-02,
         -3.0647112192e-02,  1.0716815604e-02,  1.0748643520e-02,
          3.8482084740e-02, -3.6868394181e-02, -1.8048595919e-01,
         -9.5451276632e-04,  2.9865470936e-02,  1.5637783308e-01,
          3.0717873915e-02,  9.8216771933e-02,  2.0992925350e-01,
         -4.6670187067e-02,  6.6534217390e-02, -7.5572784908e-02,
         -8.3341479313e-02,  3.9583966394e-02, -1.5289004072e-01,
          5.1686982321e-02,  1.0375886009e-02,  6.4101562631e-02,
         -7.2134769395e-02,  5.8626440537e-02, -2.4840573470e-02,
          3.7583579056e-02, -6.1299657195e-02, -1.8328729674e-02,
          1.4328861879e-05, -2.9195741991e-02, -1.1244289944e-02,
         -2.0783997861e-02, -2.1540184874e-02,  1.7162233601e-01,
          6.2169671646e-02, -2.4458641697e-02,  2.7380058923e-02,
          6.0489738854e-02,  4.7428909913e-02,  5.1196209416e-03,
         -1.5383737584e-02, -1.9037842872e-03, -3.5992432769e-02,
         -9.8095624607e-03,  2.8021255413e-02,  1.6961447271e-03,
          1.6993061876e-02, -5.6680193003e-02, -4.9730785134e-02,
          8.4912836503e-03, -1.1156714340e-02,  7.2715503579e-02,
         -4.4012352211e-02,  2.7494705880e-02,  9.4066310011e-03,
          6.1439015011e-02, -6.7264135870e-02,  5.8193951245e-02,
          5.9395811665e-02, -5.5350126101e-02,  3.0632017408e-02,
         -5.6660616418e-04, -1.0228110039e-01, -5.6582823266e-02,
          4.4348047532e-02,  7.3541688390e-02, -2.8334157565e-02,
         -3.2323862859e-02, -1.0424615859e-01, -4.4124891342e-02,
         -3.0137378862e-02, -4.9900770501e-02,  2.9070869704e-02,
          1.1651404818e-01,  6.1563101174e-02,  1.9440329938e-02,
         -1.3013691870e-01, -1.0367305279e-01, -1.3437340053e-01,
         -5.6708111147e-02,  1.3347636812e-01, -8.6506186701e-02]],
       device='cuda:0')
Additional parameters check:
 std:
 tensor([[[0.0705757621, 0.0435204831, 0.0435204831, 0.0435204831],
         [0.0733648495, 0.0458398530, 0.0458398530, 0.0458398530]]],
       device='cuda:0') 
avg:
 tensor([[[0.0264868912, 0.0000000000, 0.0000000000, 0.0000000000],
         [0.0303578252, 0.0000000000, 0.0000000000, 0.0000000000]]],
       device='cuda:0') 
use_std_avg True
Epoch: 0         , Batch: 0         , lossE:   3.608510 eV/atom, lossF:   0.488021 eV/A, time:      0.059 s
Rank 0: Model saved to ./freeze_model.pytorch
Training complete. Time elapsed:      0.082 s


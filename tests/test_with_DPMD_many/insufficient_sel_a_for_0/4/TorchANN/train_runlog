cuDNN version:  7401
Number of GPUs:  1
Using /tmp/torch_extensions as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /tmp/torch_extensions/test_from_cpp/build.ninja...
Building extension module test_from_cpp...
ninja: no work to do.
Loading extension module test_from_cpp...
All parameters:
>>> cutoff_1: 7.700000e+00
>>> cutoff_2: 8.000000e+00
>>> cutoff_3: 0.000000e+00
>>> cutoff_max: 8.000000e+00
>>> N_types_all_frame:  2
>>> type_index_all_frame: [15, 79]
>>> N_Atoms_max: 46
>>> SEL_A_max: 308
>>> Nframes_tot:  2
>>> sym_coord_type:  1
>>> N_sym_coord: 1232
>>> batch_size:  2
>>> stop_epoch:  1
>>> num_filter_layer:  3
>>> filter_neuron: [120, 64, 103]
>>> axis_neuron:  1
>>> num_fitting_layer:  4
>>> fitting_neuron: [268, 206, 116, 65]
>>> start_lr: 5.000000e-04
>>> (Not used)decay_steps: -1
>>> decay_epoch:  1
>>> decay_rate: 9.500000e-01
>>> start_pref_e: 1.000000e+00
>>> limit_pref_e: 1.000000e+00
>>> start_pref_f: 1.000000e+04
>>> limit_pref_f: 1.000000e+00
>>> check_step: 1000
>>> output_epoch: 10
>>> save_epoch: 10

Total number of frames:  2
Number of atoms aligned:  46
COORD_Reshape: shape =  (2, 138)
FORCE_Reshape: shape =  (2, 138)
TYPE_Reshape: shape =  (2, 46)
NEI_IDX_Reshape: shape =  (2, 14168)
NEI_COORD_Reshape: shape =  (2, 42504)
NEI_TYPE_Reshape: shape =  (28336,)
Data pre-processing complete. Building net work.

one_batch_net(
  (batch_norm): BatchNorm1d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (filter_input): ModuleList(
    (0): ModuleList(
      (0): Linear(in_features=1, out_features=120, bias=True)
      (1): Linear(in_features=1, out_features=120, bias=True)
    )
    (1): ModuleList(
      (0): Linear(in_features=1, out_features=120, bias=True)
      (1): Linear(in_features=1, out_features=120, bias=True)
    )
  )
  (filter_hidden): ModuleList(
    (0): ModuleList(
      (0): ModuleList(
        (0): Linear(in_features=120, out_features=64, bias=True)
        (1): Linear(in_features=64, out_features=103, bias=True)
      )
      (1): ModuleList(
        (0): Linear(in_features=120, out_features=64, bias=True)
        (1): Linear(in_features=64, out_features=103, bias=True)
      )
    )
    (1): ModuleList(
      (0): ModuleList(
        (0): Linear(in_features=120, out_features=64, bias=True)
        (1): Linear(in_features=64, out_features=103, bias=True)
      )
      (1): ModuleList(
        (0): Linear(in_features=120, out_features=64, bias=True)
        (1): Linear(in_features=64, out_features=103, bias=True)
      )
    )
  )
  (fitting_input): ModuleList(
    (0): Linear(in_features=103, out_features=268, bias=True)
    (1): Linear(in_features=103, out_features=268, bias=True)
  )
  (fitting_hidden): ModuleList(
    (0): ModuleList(
      (0): Linear(in_features=268, out_features=206, bias=True)
      (1): Linear(in_features=206, out_features=116, bias=True)
      (2): Linear(in_features=116, out_features=65, bias=True)
    )
    (1): ModuleList(
      (0): Linear(in_features=268, out_features=206, bias=True)
      (1): Linear(in_features=206, out_features=116, bias=True)
      (2): Linear(in_features=116, out_features=65, bias=True)
    )
  )
  (fitting_out): ModuleList(
    (0): Linear(in_features=65, out_features=1, bias=True)
    (1): Linear(in_features=65, out_features=1, bias=True)
  )
)
Number of parameters in the net: 288746
Start training using device:  cuda , count:  1
LR update: lr = 0.000500
Force check:
 tensor([[ 7.9103676471e-04,  8.3454052990e-04, -7.3400307760e-03,
         -1.1392214515e-04,  5.2222030983e-03,  1.8050798509e-02,
          7.5272391602e-03, -2.0581770572e-02,  4.0455179360e-02,
          2.7332230179e-02,  1.8626291191e-02, -1.1749886834e-02,
         -5.7179367805e-03,  1.0938314269e-03,  6.9678724239e-03,
         -1.7549830879e-02,  3.1847337322e-02,  4.1230833783e-03,
         -1.3805990039e-02, -3.5284639740e-02, -1.7422283392e-02,
         -2.5854088425e-04,  5.9046770823e-03,  1.1868731486e-03,
          3.4351469154e-03, -1.8501505028e-03,  3.1800416847e-03,
          1.1352390301e-02, -1.3877327684e-03,  5.2174258753e-03,
          3.6463024476e-03,  1.8017851154e-03,  7.4261152904e-03,
          3.0496882049e-03,  2.3027284462e-03, -1.7740807111e-02,
         -5.7161886971e-03,  1.0467270910e-02, -1.8847514337e-02,
         -1.2585784521e-02, -4.9083620894e-03, -1.0388061401e-02,
          8.3068116525e-03,  2.8563207224e-03, -6.4430470810e-03,
         -6.9332658688e-03,  9.4154434728e-04,  6.1667066880e-04,
          1.3629606385e-04,  2.3647686252e-02, -1.4614179104e-03,
          5.9839793230e-03,  3.6834061046e-03,  1.0889940475e-02,
          1.2237298658e-02, -2.6278218725e-03, -1.2665477250e-02,
          1.3648334479e-03,  1.1774214654e-02, -8.0101376803e-03,
          6.8357697998e-03,  1.4039703509e-03,  8.6535429439e-03,
         -2.5384700138e-03, -1.2048432487e-02,  2.0247587531e-03,
         -2.8105226548e-04, -1.0005620413e-02,  6.5837540437e-03,
         -4.5967800061e-03,  2.2782697402e-03,  6.2484153041e-03,
          8.1081722574e-03,  1.1853381755e-02,  9.9179966563e-03,
          3.5174805003e-04,  7.5810853990e-03, -1.4011226293e-03,
         -1.4366100789e-02, -4.6794836304e-03,  7.1823367833e-03,
         -5.5865891839e-04,  1.7254067652e-04, -1.1488291657e-02,
          2.4355984831e-03, -3.8242144541e-03, -5.5334471131e-03,
         -1.1856919463e-02, -4.9208085771e-03,  5.2839424562e-03,
         -1.4932156606e-02, -6.7495928124e-03, -1.1662247475e-02,
         -3.0920425910e-03, -6.4488373950e-03, -7.4414964832e-03,
         -1.0458306266e-02, -2.0965074406e-03, -4.7001554418e-03,
          1.7514772966e-03,  1.0603666097e-02, -1.4413392609e-02,
         -2.3041701528e-03, -2.0086494527e-03, -6.7645776721e-03,
          2.6332267600e-03, -2.2942392634e-03, -1.0689700094e-02,
          5.0720925733e-03,  3.1868815840e-03,  1.2744675410e-02,
         -1.2014023679e-03,  3.4830247160e-03,  3.7876049424e-03,
          1.3183344276e-03, -2.5242201277e-02,  1.2905271010e-02,
          3.5363463470e-04,  1.4530991727e-02,  2.0541207216e-03,
          3.3228551864e-03,  7.7466319587e-04, -1.0691630109e-02,
         -1.5729569689e-02,  6.2290657230e-05,  1.7047922790e-04,
          5.3645197893e-03, -1.8366064505e-02, -4.9346322437e-03,
         -7.5678071273e-03,  1.0355763679e-04, -2.4686142735e-03,
          1.0568084312e-03, -2.9062434275e-03,  1.4231585603e-02,
          2.8397405264e-02, -8.8067880571e-03,  1.4355486902e-02],
        [ 4.9682417569e-03, -5.6410239740e-03, -5.9996753051e-03,
          9.1040850141e-03, -5.3247045432e-03, -2.1188825046e-02,
         -1.6899388851e-02, -2.0895846945e-03, -2.0442187991e-02,
         -1.7233578640e-02, -1.7404720918e-02,  3.1008931892e-02,
          1.9491651057e-03,  5.7055470327e-04,  2.9845407948e-03,
          2.7211010773e-02,  2.3329608953e-02,  2.1500491396e-02,
          3.4963950453e-02, -3.1001638937e-02, -1.7554334955e-02,
         -7.8401594647e-03,  4.8599303206e-03, -5.6440510100e-04,
          9.6922895241e-03, -1.1388704008e-03, -4.5784199242e-03,
          7.1350431512e-03, -5.0404867597e-04,  4.3423634194e-03,
          9.4621816560e-03,  3.0119388677e-03,  1.8905019697e-03,
         -1.2359171233e-03,  1.6344791018e-02,  5.5687292679e-03,
          4.7671680218e-03, -1.9105848391e-02, -1.5021546576e-02,
          2.6079708228e-03, -6.8392100700e-03, -4.4102001160e-04,
          2.5561187914e-03,  2.1420624857e-04, -1.6786176387e-02,
         -3.0869986916e-03,  5.6791988331e-03,  1.8119058119e-03,
          2.7472606009e-03,  6.9067686714e-03,  3.0201275654e-05,
         -1.3202381397e-02,  1.7722300228e-02, -7.3715338322e-03,
         -1.1960247467e-02,  1.0512376959e-02, -1.3769486788e-02,
          3.8286930483e-03,  2.0489052444e-03,  2.2257944301e-02,
         -1.6656393871e-03, -1.1306248143e-02, -1.6215953805e-02,
          8.3223034394e-03, -7.9226183336e-03, -1.1977868577e-02,
          5.9406961259e-03, -1.3069357123e-02, -5.2238305667e-03,
          9.4987127439e-03,  1.6457935579e-03, -5.3519108058e-03,
         -3.9199897178e-03, -1.6486629449e-02, -1.5648788594e-02,
         -2.0464766830e-02,  1.4764629364e-03,  9.4938984690e-03,
         -2.6428292899e-03,  1.0143278755e-02, -5.4652983123e-04,
         -8.6155776474e-03,  1.3859841342e-02, -5.2385953332e-03,
          4.8719669491e-03,  8.7703754009e-03, -3.8032497444e-03,
         -1.5860154434e-02, -2.7152092134e-03,  1.8663141414e-03,
         -1.1985319533e-03, -2.0361392690e-03,  2.1915497217e-02,
         -7.2283671927e-03,  4.1297612530e-03,  6.9669098223e-03,
         -6.5547277724e-03, -8.9310662290e-03,  1.2260459809e-02,
          2.7656717507e-05, -6.0289208716e-03, -1.0169422112e-02,
         -1.9197253239e-03,  6.9577671716e-03, -2.2291645848e-03,
         -4.1624279221e-03, -1.8255613475e-02,  2.9936819089e-02,
         -3.0209007056e-03,  6.8012453416e-03,  1.2064252435e-02,
          5.3878405435e-03,  9.6645699619e-04,  1.3952972005e-02,
          3.8304454039e-03, -6.1586947957e-03,  1.4149664791e-02,
          2.7137804400e-02,  1.5069445355e-02,  5.4027851462e-03,
         -7.5676384536e-03, -2.4930947124e-04, -1.5265394152e-02,
         -9.9492768513e-03,  7.4717236099e-03, -1.7527752882e-02,
         -2.0344694008e-02, -1.4071091798e-02, -5.4619651015e-03,
          1.1994845372e-02,  7.9048964563e-03,  1.7386974788e-02,
         -1.1970405481e-02,  8.5091165484e-03, -1.6012926877e-03,
          5.3887419106e-04,  1.1373804004e-02,  3.1871728533e-03]],
       device='cuda:0')
Additional parameters check:
 std:
 tensor([[[0.0863894742, 0.0555285614, 0.0555285614, 0.0555285614],
         [0.0879233537, 0.0575689555, 0.0575689555, 0.0575689555]]],
       device='cuda:0') 
avg:
 tensor([[[0.0422810370, 0.0000000000, 0.0000000000, 0.0000000000],
         [0.0470345684, 0.0000000000, 0.0000000000, 0.0000000000]]],
       device='cuda:0') 
use_std_avg True
Epoch: 0         , Batch: 0         , lossE:   3.298183 eV/atom, lossF:   0.322958 eV/A, time:      0.057 s
Rank 0: Model saved to ./freeze_model.pytorch
Training complete. Time elapsed:      0.078 s

